{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14672dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load model and threshold\n",
    "model = joblib.load(\"lieferschein_header_detector.pkl\")\n",
    "with open(\"lieferschein_threshold.txt\", \"r\") as f:\n",
    "    threshold = float(f.read())\n",
    "\n",
    "# Feature extraction (must match training logic)\n",
    "def extract_features(text):\n",
    "    text_length = len(text)\n",
    "    num_lines = text.count('\\n')\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    keywords = [\"lieferschein\", \"bestellnr\", \"lieferdatum\", \"kundennr\", \"iban\", \"mwst\"]\n",
    "    num_keywords_matched = sum(1 for kw in keywords if re.search(rf\"\\b{kw}\\b\", text, re.IGNORECASE))\n",
    "\n",
    "    contains_lieferschein = int(\"lieferschein\" in text.lower())\n",
    "    contains_bestellnr = int(\"bestellnr\" in text.lower())\n",
    "    contains_lieferdatum = int(\"lieferdatum\" in text.lower())\n",
    "    contains_kundennr = int(\"kundennr\" in text.lower())\n",
    "    contains_iban = int(\"iban\" in text)\n",
    "    contains_mwst = int(\"mwst\" in text.lower())\n",
    "\n",
    "    uppercase_chars = sum(1 for c in text if c.isupper())\n",
    "    uppercase_ratio = uppercase_chars / text_length if text_length else 0\n",
    "\n",
    "    num_dates = len(re.findall(r'\\d{2}\\.\\d{2}\\.\\d{4}', text))\n",
    "    avg_spaces_per_line = sum(line.count(' ') for line in text.split('\\n')) / (num_lines or 1)\n",
    "\n",
    "    num_numeric_blocks = len(re.findall(r'\\b\\d{4,}\\b', text))\n",
    "    avg_word_length = sum(len(w) for w in words) / len(words) if words else 0\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    first_line = lines[0] if lines else \"\"\n",
    "    first_line_caps_ratio = sum(1 for c in first_line if c.isupper()) / len(first_line) if len(first_line) > 0 else 0\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'text_length': text_length,\n",
    "        'num_lines': num_lines,\n",
    "        'num_words': num_words,\n",
    "        'contains_lieferschein': contains_lieferschein,\n",
    "        'contains_bestellnr': contains_bestellnr,\n",
    "        'contains_lieferdatum': contains_lieferdatum,\n",
    "        'contains_kundennr': contains_kundennr,\n",
    "        'contains_iban': contains_iban,\n",
    "        'contains_mwst': contains_mwst,\n",
    "        'uppercase_ratio': uppercase_ratio,\n",
    "        'num_dates': num_dates,\n",
    "        'avg_spaces_per_line': avg_spaces_per_line,\n",
    "        'num_keywords_matched': num_keywords_matched,\n",
    "        'num_numeric_blocks': num_numeric_blocks,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'first_line_caps_ratio': first_line_caps_ratio\n",
    "    }])\n",
    "\n",
    "# Prediction function\n",
    "def predict_header_page(pdf_path, page_number=0):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    if page_number >= len(reader.pages):\n",
    "        raise ValueError(\"Page number out of range\")\n",
    "    text = reader.pages[page_number].extract_text() or \"\"\n",
    "    features = extract_features(text)\n",
    "    prob = model.predict_proba(features)[0][1]\n",
    "    return int(prob > threshold)\n",
    "\n",
    "# Copy SAP_data to current_data\n",
    "shutil.copy(\"data/SAP_data.json\", \"data/current_data.json\")\n",
    "\n",
    "# Load SAP data\n",
    "with open(\"data/current_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sap_data = json.load(f)\n",
    "\n",
    "# Normalize date format in current_data\n",
    "for entry in sap_data:\n",
    "    raw_date = entry.get(\"Delivery Note Date\")\n",
    "    if raw_date:\n",
    "        try:\n",
    "            dt = datetime.fromisoformat(raw_date.replace(\"T00:00:00.000\", \"\"))\n",
    "            entry[\"Delivery Note Date\"] = dt.strftime(\"%Y-%m-%d\")\n",
    "        except Exception:\n",
    "            entry[\"Delivery Note Date\"] = \"\"\n",
    "\n",
    "# Save updated current_data.json\n",
    "with open(\"data/current_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sap_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Prepare lookups\n",
    "delivery_notes = set(str(entry[\"Delivery Note Number\"]).strip() for entry in sap_data)\n",
    "company_names = set(entry[\"Vendor - Name 1\"].strip() for entry in sap_data if entry[\"Vendor - Name 1\"])\n",
    "\n",
    "def build_relaxed_pattern(number):\n",
    "    return re.compile(\"\\\\s*\".join(re.escape(d) for d in number))\n",
    "\n",
    "delivery_note_patterns = {\n",
    "    note: build_relaxed_pattern(note) for note in delivery_notes\n",
    "}\n",
    "\n",
    "def build_name_pattern(name):\n",
    "    cleaned = re.sub(r'\\s+', '', name.lower())\n",
    "    return re.compile(\"\\\\s*\".join(re.escape(char) for char in cleaned), re.IGNORECASE)\n",
    "\n",
    "company_name_patterns = {\n",
    "    name: build_name_pattern(name) for name in company_names\n",
    "}\n",
    "\n",
    "def normalize_address_variant(s):\n",
    "    return (\n",
    "        s.replace(\"\\u00df\", \"ss\")\n",
    "         .replace(\"Straße\", \"Strafle\")\n",
    "         .replace(\"Strasse\", \"Strafle\")\n",
    "         .replace(\" \", \"\")\n",
    "         .replace(\",\", \"\")\n",
    "         .replace(\"-\", \"\")\n",
    "         .replace(\".\", \"\")\n",
    "         .replace(\"\\u2022\", \"\")\n",
    "         .lower()\n",
    "    )\n",
    "\n",
    "address_variants = []\n",
    "normalized_address_variants = []\n",
    "for entry in sap_data:\n",
    "    street = entry.get(\"Vendor - Address - Street\", \"\")\n",
    "    number = str(entry.get(\"Vendor - Address - Number\", \"\")).strip()\n",
    "    zip_code = str(entry.get(\"Vendor - Address - ZIP Code\", \"\")).strip()\n",
    "    city = entry.get(\"Vendor - Address - City\", \"\")\n",
    "    country = entry.get(\"Vendor - Address - Country\", \"\")\n",
    "\n",
    "    if not street or not number:\n",
    "        continue\n",
    "\n",
    "    variants = [\n",
    "        f\"{street} {number}\",\n",
    "        f\"{street}- {number}\",\n",
    "        f\"{number} {street}\",\n",
    "        f\"{street} {number}, {zip_code} {city}\",\n",
    "        f\"{street} {number}, {city}\",\n",
    "        f\"{street} {number}, {city}, {country}\",\n",
    "        f\"{street} {number} • {zip_code} {city}\"\n",
    "    ]\n",
    "\n",
    "    for v in variants:\n",
    "        cleaned = v.strip()\n",
    "        if cleaned:\n",
    "            address_variants.append(cleaned)\n",
    "            normalized_address_variants.append(normalize_address_variant(cleaned))\n",
    "\n",
    "raw_to_standard_date = {}\n",
    "for entry in sap_data:\n",
    "    date_str = entry.get(\"Delivery Note Date\")\n",
    "    if not date_str:\n",
    "        continue\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(date_str)\n",
    "        formats = [\n",
    "            dt.strftime(\"%d.%m.%Y\"), dt.strftime(\"%Y-%m-%d\"), dt.strftime(\"%d/%m/%Y\"),\n",
    "            dt.strftime(\"%d.%m.%y\"), dt.strftime(\"%d %b %Y\"), dt.strftime(\"%d %B %Y\")\n",
    "        ]\n",
    "        for f in formats:\n",
    "            raw_to_standard_date[f] = dt.strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "company_prefixes = set()\n",
    "for entry in sap_data:\n",
    "    name = entry.get(\"Vendor - Name 1\", \"\").strip()\n",
    "    if len(name) >= 7:\n",
    "        company_prefixes.add(name[:7])\n",
    "\n",
    "zip_code_variants = set()\n",
    "for entry in sap_data:\n",
    "    zip_code = str(entry.get(\"Vendor - Address - ZIP Code\", \"\")).strip()\n",
    "    if zip_code:\n",
    "        zip_code_variants.add(zip_code)\n",
    "\n",
    "def analyze_batch_pdf(pdf_path):\n",
    "    result = []\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            page_number = i + 1\n",
    "            text = page.extract_text() or \"\"\n",
    "            text_lower = text.lower()\n",
    "            text_flat = normalize_address_variant(text)\n",
    "            text_normalized = text_lower.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "\n",
    "            delivery_note = \"not known\"\n",
    "            for note, pattern in delivery_note_patterns.items():\n",
    "                if pattern.search(text):\n",
    "                    delivery_note = note\n",
    "                    break\n",
    "\n",
    "            company_name = \"not known\"\n",
    "            for name, pattern in company_name_patterns.items():\n",
    "                if pattern.search(text):\n",
    "                    company_name = name\n",
    "                    break\n",
    "\n",
    "            address = next(\n",
    "                (original for original, norm in zip(address_variants, normalized_address_variants) if norm in text_flat),\n",
    "                \"not known\"\n",
    "            )\n",
    "\n",
    "            matched_raw_date = next((d for d in raw_to_standard_date if d in text), None)\n",
    "            date = raw_to_standard_date.get(matched_raw_date, \"not known\")\n",
    "            mjahr = date[:4] if date != \"not known\" else \"not known\"\n",
    "\n",
    "            company_prefix = next(\n",
    "                (prefix for prefix in company_prefixes if prefix.lower().replace(\" \", \"\") in text_normalized),\n",
    "                \"not known\"\n",
    "            )\n",
    "\n",
    "            zip_code = \"not known\"\n",
    "            if address == \"not known\":\n",
    "                zip_code = next((z for z in zip_code_variants if z in text), \"not known\")\n",
    "\n",
    "            seite = \"not known\"\n",
    "            match = re.search(r\"Seite.{0,5}\", text)\n",
    "            if match:\n",
    "                seite_raw = match.group()\n",
    "                seite = re.sub(r\"[A-Za-z\\s]\", \"\", seite_raw)\n",
    "\n",
    "            is_header = predict_header_page(pdf_path, i)\n",
    "\n",
    "            result.append({\n",
    "                \"page\": page_number,\n",
    "                \"delivery_note\": delivery_note,\n",
    "                \"company_name\": company_name,\n",
    "                \"address\": address,\n",
    "                \"date\": date,\n",
    "                \"company_prefix\": company_prefix,\n",
    "                \"zip_code\": zip_code,\n",
    "                \"MJAHR\": mjahr,\n",
    "                \"Seite\": seite,\n",
    "                \"is_header_page\": is_header\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {pdf_path}: {e}\")\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    base_dir = \"data\"\n",
    "    output = {}\n",
    "\n",
    "    for filename in os.listdir(base_dir):\n",
    "        if filename.endswith(\".pdf\") and filename.startswith(\"batch_\"):\n",
    "            batch_path = os.path.join(base_dir, filename)\n",
    "            batch_name = filename.replace(\".pdf\", \"\")\n",
    "            output[batch_name] = analyze_batch_pdf(batch_path)\n",
    "\n",
    "    with open(\"data/current_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        current_data = json.load(f)\n",
    "\n",
    "    # First matching phase\n",
    "    for batch in output.values():\n",
    "        for entry in batch:\n",
    "            dn = entry[\"delivery_note\"]\n",
    "            matched = next((row for row in current_data if str(row[\"Delivery Note Number\"]).strip() == dn), None)\n",
    "            entry[\"MBLNR\"] = matched[\"MBLNR\"] if matched else \"not known\"\n",
    "\n",
    "    # Second matching phase\n",
    "    for batch in output.values():\n",
    "        for entry in batch:\n",
    "            if entry[\"MBLNR\"] != \"not known\":\n",
    "                continue\n",
    "            name = entry[\"company_name\"]\n",
    "            date = entry[\"date\"]\n",
    "            zip_code = entry[\"zip_code\"]\n",
    "            matched = next(\n",
    "                (\n",
    "                    row for row in current_data\n",
    "                    if row.get(\"Vendor - Name 1\") == name and\n",
    "                       row.get(\"Delivery Note Date\") == date and\n",
    "                       str(row.get(\"Vendor - Address - ZIP Code\", \"\")).strip() == zip_code\n",
    "                ),\n",
    "                None\n",
    "            )\n",
    "            if matched:\n",
    "                entry[\"MBLNR\"] = matched[\"MBLNR\"]\n",
    "\n",
    "    with open(\"output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3c95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
